{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR , ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for availability of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to extract data from the csv and scale it using min-max scaling. Further commented code can be used to get the correlation heatmap and scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, path, input_features, output_features):\n",
    "        self.path = path\n",
    "        self.inp = input_features\n",
    "        self.out = output_features\n",
    "\n",
    "    def extract(self):\n",
    "        df = pd.read_csv(self.path)\n",
    "        first_non_zero_index = (df[['Ia_amps', 'Ib_amps', 'Ic_amps']] != 0).any(axis=1).idxmax()\n",
    "        df = df.loc[first_non_zero_index:]\n",
    "        df = df.reset_index(drop=True)\n",
    "        # correlation_matrix = df.corr()\n",
    "        # plt.figure(figsize=(10, 8))\n",
    "        # sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "        # plt.title('Correlation Heatmap')\n",
    "        # plt.show()\n",
    "        # fig, axes = plt.subplots(nrows=len(self.out), ncols=len(self.inp), figsize=(15, 10))\n",
    "        # Create individual scatter plots\n",
    "        # for i, output_var in enumerate(self.out):\n",
    "        #     for j, input_var in enumerate(self.inp):\n",
    "        #         sns.scatterplot(data=df, x=input_var, y=output_var, ax=axes[i, j], label=input_var)\n",
    "        #         axes[i, j].set_xlabel(input_var)\n",
    "        #         axes[i, j].set_ylabel(output_var)\n",
    "        #         axes[i, j].legend()\n",
    "\n",
    "        # plt.suptitle('Scatter Plots: Currents vs. Input Variables', y=1.02)\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        inp_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        out_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        # df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "        # df = df.drop_duplicates()\n",
    "        X = df[self.inp]\n",
    "        y = df[self.out]\n",
    "        X = pd.DataFrame(inp_scaler.fit_transform(X), columns=X.columns)\n",
    "        y = pd.DataFrame(out_scaler.fit_transform(y), columns=y.columns)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.35, shuffle=True)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.15, shuffle=True)\n",
    "        X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "        X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "        X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "        y_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val, inp_scaler, out_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the cell below can change the variables used as input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['GaH_V', 'GbH_V', 'GcH_V', 'loadTorque_Nm', 'dcI_amps', 'speed_radps', 'mAngle_rad'] #['mAngle_rad'] # ,\n",
    "output_columns = ['Ia_amps', 'Ib_amps', 'Ic_amps']\n",
    "data = Data('/content/drive/MyDrive/PMSM.csv', input_columns, output_columns)\n",
    "train_in, test_in, val_in, train_out, test_out, val_out, inp_scaler, out_scaler = data.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model designed to have few layers, better inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.binary_signal_branch = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.speed_branch = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.combine_layer = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.phase_output_layer = nn.Linear(512, 3)\n",
    "\n",
    "    def forward(self, x_binary, x_continuous):\n",
    "        binary_signal_out = self.binary_signal_branch(x_binary)\n",
    "        speed_out = self.speed_branch(x_continuous)\n",
    "        combined = torch.cat((binary_signal_out, speed_out), dim=1)\n",
    "        combined_out = self.combine_layer(combined)\n",
    "        phase_prediction = self.phase_output_layer(combined_out)\n",
    "        return phase_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below class is used to train, validate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motor(nn.Module):\n",
    "    def __init__(self, train_in, train_out, val_in, val_out, test_in, test_out, criterion, batch_size):\n",
    "        super(Motor, self).__init__()\n",
    "\n",
    "        # Create DataLoader for training data\n",
    "        train_dataset = TensorDataset(train_in[:, :3], train_in[:, 3:], train_out)\n",
    "        self.trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "        # Create DataLoader for validation data\n",
    "        val_dataset = TensorDataset(val_in[:, :3], val_in[:, 3:], val_out)\n",
    "        self.valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "        # Store test data and criterion\n",
    "        self.test_in = test_in.to('cuda')\n",
    "        self.test_out = test_out.to('cuda')\n",
    "        self.criterion = criterion\n",
    "\n",
    "        # Lists to store training and validation losses\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def train(self, epochs, optimizer, model, scheduler):\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0\n",
    "\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            progress_bar = tqdm(enumerate(self.trainloader), total=len(self.trainloader), desc=f'Epoch {epoch}', leave=False)\n",
    "            for batch_idx, (X_bin, X_conti, y_batch) in progress_bar:\n",
    "            # for X_bin, X_conti, y_batch in self.trainloader:\n",
    "                X_bin, X_conti, y_batch = X_bin.to('cuda'), X_conti.to('cuda'), y_batch.to('cuda')\n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(X_bin, X_conti)\n",
    "                loss = self.criterion(predictions, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X_bin_val, X_conti_val, y_val_batch in self.valloader:\n",
    "                    X_bin_val, X_conti_val, y_val_batch = X_bin_val.to('cuda'), X_conti_val.to('cuda'), y_val_batch.to('cuda')\n",
    "                    val_predictions = model(X_bin_val, X_conti_val)\n",
    "                    val_loss += self.criterion(val_predictions, y_val_batch).item()\n",
    "\n",
    "            # Update learning rate with scheduler based on training loss\n",
    "            scheduler.step(train_loss)\n",
    "\n",
    "            # Log training and validation losses\n",
    "            self.train_losses.append(train_loss / len(self.trainloader))\n",
    "            self.val_losses.append(val_loss / len(self.valloader))\n",
    "\n",
    "            # Print training and validation loss\n",
    "            print(f'Epoch {epoch}: Train loss = {self.train_losses[-1]}, Val loss = {self.val_losses[-1]}')\n",
    "\n",
    "            # Check if the current model has the best validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "        # Load the best model state\n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        # Plot the training and validation curves\n",
    "        self.plot_losses()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def test(self, model):\n",
    "        model.eval()\n",
    "        preds = model(self.test_in[:, :3], self.test_in[:, 3:])\n",
    "        test_loss = torch.sum(self.criterion(preds, self.test_out))\n",
    "        print(f'Test loss = {test_loss}')\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.plot(self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "motor = Motor(train_in, train_out, val_in, val_out, test_in, test_out, criterion, 32)\n",
    "model = Model().to('cuda')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.000001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "model = motor.train(5, optimizer, model, scheduler)\n",
    "motor.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'loss_0.00082_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to('cuda')\n",
    "model.load_state_dict(torch.load('/content/best_2.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
